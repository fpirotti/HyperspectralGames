---
title: "Classificare Immagini Digitali: dai metodi classici all'Intelligenza Artificiale"
author: "Francesco Pirotti - CIRGEO / TESAF  - Università di Padova"
date: "27/8/2020" 
output:
  html_notebook: 
    toc_float: yes
  html_document:
 # ioslides_presentation: 
    highlight: tango 
    toc_float:
      
      collapsed: no
      smooth_scroll: no
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE )
```

```{r, echo=FALSE}
shiny::addResourcePath("shinyjs", system.file("srcjs", package = "shinyjs"))
```
```{r, context="server"}
shinyjs::useShinyjs(html = TRUE)
```


```{css, echo=FALSE}
.irs-bar-edge, .irs-bar {
  display:none;
}
```
<!-- ## Shiny Presentation -->

<!-- The following single character keyboard shortcuts enable alternate display modes: -->

<!-- 'f': enable fullscreen mode  -->
<!-- 'w': toggle widescreen mode  -->
<!-- 'o': enable overview mode  -->
<!-- 'h': enable code highlight mode  -->
<!-- 'p': show presenter notes -->

<!-- Pressing Esc exits all of these modes -->



```{css}

* {box-sizing: border-box;}

.shiny-notification {
              height: 200px;
              width: 800px;
              position:fixed;
              top: calc(50% - 50px);;
              left: calc(50% - 400px);;
            }
.img-zoom-container {
  position: relative;
}

.img-zoom-lens {
  position: absolute;
  border: 0px solid #d4d4d4;
  /*set the size of the lens:*/
  width: 40px;
  height: 40px;
}

div.main-container{
  max-width:9000px !important;  
}

.img-zoom-result {
  border: 2px solid #d4d4d4;
  /*set the size of the result div:*/
  width: 220px;
  height: 220px;
}

```



 ```{js}
 var initialized = false;
 
 $('#plot1').on('DOMSubtreeModified', 'img', function(){
  imageZoom( this, "myresult" );
});

 $('#plot2').on('DOMSubtreeModified', 'img', function(){
  imageZoom( this, "myresult2" );
});

 function imageZoom(img, resultID) {
 
  var  lens, result, cx, cy;
  // img = document.getElementById(imgID).children[0];
  result = document.getElementById(resultID);
  
  /*create lens:*/
  lens = document.createElement("DIV");
  lens.setAttribute("class", "img-zoom-lens");
 
  /*insert lens:*/
  img.parentElement.insertBefore(lens, img);
  /*calculate the ratio between result DIV and lens:*/
  cx = result.offsetWidth / lens.offsetWidth;
  cy = result.offsetHeight / lens.offsetHeight;
  /*set background properties for the result DIV:*/
  result.style.backgroundImage = "url('" + img.src + "')";
  result.style.backgroundSize = (img.width * cx) + "px " + (img.height * cy) + "px";
  /*execute a function when someone moves the cursor over the image, or the lens:*/
  lens.addEventListener("mousemove", moveLens);
  img.addEventListener("mousemove", moveLens);
  /*and also for touch screens:*/
  lens.addEventListener("touchmove", moveLens);
  img.addEventListener("touchmove", moveLens);

  function moveLens(e) {
    var pos, x, y;
    /*prevent any other actions that may occur when moving over the image:*/
    e.preventDefault();
    /*get the cursor's x and y positions:*/
    pos = getCursorPos(e);
    /*calculate the position of the lens:*/
    x = pos.x - (lens.offsetWidth / 2);
    y = pos.y - (lens.offsetHeight / 2);
    /*prevent the lens from being positioned outside the image:*/
    if (x > img.width - lens.offsetWidth) {x = img.width - lens.offsetWidth;}
    if (x < 0) {x = 0;}
    if (y > img.height - lens.offsetHeight) {y = img.height - lens.offsetHeight;}
    if (y < 0) {y = 0;}
    /*set the position of the lens:*/
    lens.style.left = x + "px";
    lens.style.top = y + "px";
    /*display what the lens "sees":*/
    result.style.backgroundPosition = "-" + (x * cx) + "px -" + (y * cy) + "px";
  }
  function getCursorPos(e) {
    var a, x = 0, y = 0;
    e = e || window.event;
    /*get the x and y positions of the image:*/
    a = img.getBoundingClientRect();
    /*calculate the cursor's x and y coordinates, relative to the image:*/
    x = e.pageX - a.left;
    y = e.pageY - a.top;
    /*consider any page scrolling:*/
    x = x - window.pageXOffset;
    y = y - window.pageYOffset;
    return {x : x, y : y};
  }
}
 
 
 
 
``` 


```{r message=FALSE }

library(shinyWidgets)
library(raster)
library(rgdal) 
library(ggplot2) 
library(plotly)
library(readr) 
library(dplyr)
library(reshape2)
library(shinyjs)
library(rasterVis)
library(rasclass)
library(dygraphs)
library(h2o) ## A.I. library
useShinyjs(rmd = TRUE)

```
 

```{r message=FALSE }

myImages<-list()

img.file<-"test/T32TQR_20180424_small.tif" 
# vnir.file2<-"/archivio/home/pirotti/Google Drive/RAD_3451-1_VNIR_1800_SN00852_22000us_2020-02-11T144756_raw_rad2.tif" 
  
myImage<-raster::brick(img.file, values=TRUE) 
 
# myImages[['VNIR2']]<-raster::brick(vnir.file2)
# 
bands<-c( "490nm", "560nm", "665nm", "705nm", "740nm", "783nm", "842nm", "865nm", "1610nm", "2190nm" )  
names(myImage)<- bands
  
 

### here we extract wavelengths from the band names
bands.wavelengths.nm<-readr::parse_number(names(myImage)) 

### here we put them in a string with a suffix with the sensor name, we will use this later to populate sliders for choosing the band combinations to plot and RGB image.
names(bands)<-  sprintf( "%s - %s (%s)", c(  "B2", "B3", "B4","B5", "B6","B7", "B8","B8A","B11", "B12"), bands, c(  "10m", "10m", "10m","20m", "20m","20m", "10m","20m","20m", "20m") )


``` 

## Note introduttive

**Il codice in R di questo esercizio è disponibile in GitHub [QUI](https://github.com/fpirotti/HyperspectralGames){target=_blank}**

Nelle sezioni seguenti vedrete un ritaglio di un'immagine  Sentinel-2 L2A ripresa sopra la città di Padova il giorno 24 aprile 2018 (noterete facilmente in alto a destra Prato della Valle). Sono riportate solo le [bande a 10 m e 20 m del sensore Sentinel 2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR#bands){target=_blank}.

Ogni sezione consente di interagire con l'immagine per analizzarne alcuni aspetti:

- La visualizzazione a schermo 
- La firma spettrale su un punto
- Le operazioni per la classificazione supervisionata (i.e. con il supporto dell'operatore):
  - La definizione di punti sull'immagine per l'addestramento del modello  (punti definiti anche ROI/POI - regions/points of interest, regioni/punti di interesse)
  - La creazione di modelli predittivi usanto i POI e:
    - metodi classici (Maximum Likelyhood, Spectral Angle Mapper, Minimum Distance)
    - metodi di A.I. - machine learning  (Random Forest, Support Vector Machine)
    - metodi di A.I. - Deep Learning (reti neurali multi-strato...)
- Le operazioni di analisi dell'accuratezza stimata mediante matrici di confronto con un riferimento
  - Indici aggregati di accuratezza per classe e totali (indice Kappa, AUC, precisione/recupero, falsi positivi, F-score, etc...)


All'inizio di ogni sezione viene proposto un esercizio che potete eseguire con l'interfaccia.




## Firme spettrali

**Esercizio:** raccogliete 4 firme spettrali, di elementi diversi, e.g. il canale, urbanizzato, vegetazione e la zona industriale.



### Doppio click per singola firma spettrale - singolo click per aggiungerla

```{r }

   choicesOpt <- list(
      style = sprintf("background-color:%s88;", c( "#0000ff", "#00ff00,", "#ff0000", "#a50026", "#a50026",
                                                   "#0000ff", "#00ff00,", "#ff0000", "#a50026", "#a50026" ) ) )

fluidRow(  
  
  column( 4, style="margin:0; margin-bottom:10px; width:680px !important;",    imageOutput("plot1", width = 672, height= 474,
    dblclick = "plot_dblclick", click = "plot_click" )  ),
  column(2, style="margin:0; width:220px !important; margin-bottom:10px;",
       div(
         shiny::actionButton("resetGraph", "Cancella Firme Spettrali"),
           shinyWidgets::pickerInput(
              "bandR",
              label = "Rosso",
              width = 220,
              choices = bands,
              selected = bands[[3]],
              choicesOpt = choicesOpt
            ),
           
           shinyWidgets::pickerInput(
              "bandG",
              label = "Verde",
              width = 220,
              choices = bands ,
              selected = bands[[2]]
            ),
           shinyWidgets::pickerInput(
              "bandB",
              label = "Blue",
              width = 220,
              choices = bands ,
              selected = bands[[1]]
            )
       ),
         div( id="myresult",   class="img-zoom-result", 
              div(style="border:2px solid red; width:10px; height:10px; margin:105px auto;  ") )
    ),
  
  
  
  column( 4,  style="margin:0; width:220px !important; margin-bottom:10px;",  plotlyOutput("graph1", width=500) )
  
)

output$plot1 <- renderPlot({
  
  req(input$bandR, input$bandG, input$bandB)
   
  plotRGB(
    myImage,
    r = isolate({ which(input$bandR == bands) }),
    g = isolate({ which(input$bandG == bands) }),
    b = isolate({ which(input$bandB == bands) }), 
    stretch = "hist",
    main ="Clicca per firma spettrale pixel - doppio click per aggiungere"
  )
  
})

 

observeEvent(input$plot_click, {
  
  req(input$plot_click)
  values <- gdalUtils::gdallocationinfo(img.file, input$plot_click$x,
                                input$plot_click$y, geoloc=T, valonly = T)
 
  values.num <- as.numeric(values) 
  
  x.click <- as.integer(input$plot_click$x)
  y.click <- as.integer(input$plot_click$y)

      
  plotlyProxyInvoke(plotlyProxy("graph1", session), "addTraces", list(
    list(
      x = bands.wavelengths.nm,
      y = values.num / 10000,
      type = 'scatter',
      mode = 'markers+lines',  line = list(shape = "spline")
    )
    
  ))
  
})

  

output$graph1 <- renderPlotly({
 
  input$resetGraph
  
  p <- plot_ly(type = "scatter", mode = "markers") %>% layout( 
    xaxis = list(title = "Lunghezza d'Onda (nm)"),
    yaxis = list(title = "Riflettanza Bottom-Of-Atmosphere (BOA)"),
    title = sprintf("Firme spettrale")
   ) # %>% add_trace(
  #     y = values.num / 10000,
  #     x =  bands.wavelengths.nm,
  #     mode = "markers+lines",  line = list(shape = "spline")
  # ) # %>% add_lines(  x =  bands.wavelengths.nm, y =values.num,   line = list(shape = "spline") )
  
  p
  
})

model.names <- list(RF = "Random Forest",
                    NB = "Naive Bayes",
                    GMB = "Gradient Boosting Machine",
                    SVM= "Support Vector Machine",
                    DL = "Deep Learning")
```

## Classificazione "supervisionata"

We will use only the SWIR because it is a lighter image and takes less time to process in real time and we do not want to be bored waiting for image to classify.

1. Grab some training pixels by choosing the class and start clicking on the image below.
2. Click **PLOT** if you want to redraw the points that were clicked (image is NOT auto-updated)
3. Once finished **clic "RUN"** to start training/validation/testing phase of the following models:
4. You will see a plot of signatures AND classified images



```{r  }


react <- reactiveValues(train.table = data.frame(
  id = integer(0),
  x = integer(0) ,
  y = integer(0),
  Class = character(0)
))

if (file.exists("s2.train.table.rds")) {
  react$train.table <-
    readRDS("s2.train.table.rds")
  
}

 

fluidRow( 

  column( 6,    plotOutput("plot2", width = 672, height= 474,
    dblclick = "plot_dblclick2", click = "plot_click2" )   ),
  

  column(
    width = 3,
    radioGroupButtons(
      inputId = "myClass",
      label = "Scegli la classe per ROI",
      choices =  c("Urbano", "Acqua", "Vegetazione", "Agricolo", "Altro"),
      # justified = TRUE,
      direction = "vertical",
      checkIcon = list(yes = icon("ok",
                                  lib = "glyphicon"))
    ),
    
   div(style="display:inline-block;", shinyWidgets::actionBttn("plotTrain", label = "RiDisegna", size = "xs", block = F, style = "fill",   shiny::icon("pen"))  ),
    div(style="display:inline-block;float:left",
      title = "Removes all points!!",
      shinyWidgets::actionBttn("resetTrain", label = "RESET", size = "xs",block = F, style = "fill",   shiny::icon("trash"))
    ),
    div(style="display:inline-block;float:left;",  shinyWidgets::actionBttn("runTrain",  label = "Elabora",  size = "xs", block = F, style = "fill",  shiny::icon("gear")) ),
    div( id="myresult2",   class="img-zoom-result", div(style="border:2px solid red; width:10px; height:10px; margin:105px auto;  ") ) 
  ),
  
  column(
    width = 3,
    div(style = "height:474px; overflow-y:auto;",  tableOutput("trainingTable"))
  )
  
)


 
 

output$plot2 <- renderPlot({
  req(input$plotTrain)
  
  req(input$bandR, input$bandG, input$bandB)
   
  plotRGB(
    myImage,
    r = which(input$bandR == bands),
    g = which(input$bandG == bands),
    b = which(input$bandB == bands),
    scale = 255,
    stretch = "hist"
  )
  
  isolate({
    if (shiny::isTruthy(react$train.table) && nrow(react$train.table)) {
      col <- RColorBrewer::brewer.pal(6, "Paired")
      col2 <- RColorBrewer::brewer.pal(6, "Pastel2")
      train.table.classes <- as.factor(react$train.table$Class)
      
      points(
        react$train.table$x,
        react$train.table$y,
        col = col[train.table.classes],
        bg = col2[train.table.classes],
        pch = 21
      )
      
      text(
        react$train.table$x,
        react$train.table$y,
        pos = 2,
        react$train.table$id,
        col = col[train.table.classes]
      )
      
    }
  })
  
})


output$trainingTable <- renderTable({
  react$train.table
})

observeEvent(input$resetTrain,  {
  isolate({
    react$train.table <-
      data.frame(
        id = integer(0),
        x = integer(0) ,
        y = integer(0),
        Class = character(0)
      )
  })
})

observeEvent(input$plot_click2,  {
  isolate({
    react$train.table <-
      rbind(
        react$train.table,
        list(
          id = as.integer(nrow(react$train.table) + 1),
          x = as.integer(input$plot_click2$x),
          y = as.integer(input$plot_click2$y),
          Class = input$myClass
        )
      )
  })
})



fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot3"))))

fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot4"))))

fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot5"))))


observeEvent(input$runTrain, {
  
  req(input$runTrain, react$train.table)
  
 # saveRDS(react$train.table, "s2.train.table.rds")
  
  if (nrow(react$train.table) < 10) {
    shinyWidgets::alert("Almeno 10 punti di ROI per classe", status =
                          "warning")
    shinyjs::alert("Almeno 10 punti di ROI per classe")
    return(NULL)
  }
  
  
  if (sum(table(react$train.table$Class) < 10) != 0) {
    whi <-
      paste0(collapse = ", ", names(which( table(
        react$train.table$Class
      ) < 10)))
    shinyWidgets::alert(
      sprintf(
        "Almeno 10 punti di ROI per classe.",
        whi
      ),
      status = "warning"
    )
    shinyjs::alert(sprintf(
      "Almeno 10 punti di ROI per classe! Classe/i %s hanno pochi punti ROI.",
      whi
    ))
    return(NULL)
  }
  
  ss <-
    matrix(
      data = NA,
      nrow = nrow(react$train.table),
      ncol = length( bands.wavelengths.nm)
    )
  
  withProgress(
    message = "Leggo le firme spettrali", 
    value = 0,
    min = 0,
    max = nrow(react$train.table),
    {
      for (i in 1:nrow(react$train.table)) {
        setProgress(as.integer(i), detail=sprintf("Punto %s", i))
        ss[i,] <-
          as.numeric(
            gdalUtils::gdallocationinfo(
              img.file, geoloc=T, 
              react$train.table[i, "x"]  ,
              react$train.table[i, "y"],
              valonly = T
            )
          )
      }
    }
  )
  
  if (is.null(ss)) {
    shinyjs::alert("ISNULL!")
    return(NULL)
  }
  
  train.data <-
    as.data.frame(cbind(react$train.table[c("Class")], ss))
  
  ###############################################################################
  ### from here  is only for plotting - our training data is  "train.data"
  quants <- c(0.1, 0.25, 0.5, 0.75, 0.9)
  df.with.ss2 <-
    train.data  %>%  dplyr::group_by(Class) %>% dplyr::summarize_all(function(x) {
      if (is.numeric(x))
        quantile(as.numeric(x), quants)
      else
        c(0, 0, 0, 0, 0)
    })
  
  df.with.ss2$Quantile <-
    rep(sprintf("Q%s", quants * 100), length(unique(df.with.ss2$Class)))
  #saveRDS(as.data.frame(df.with.ss2), "df.with.ss2.rds")
  
  df.with.ss3 <- reshape2::melt(df.with.ss2)
  df.with.ss4 <-
    reshape2::dcast(df.with.ss3 ,   Class + variable ~ Quantile)
  df.with.ss4$Wavelength <-
    bands.wavelengths.nm[df.with.ss4$variable]
  df.with.ss4[df.with.ss4 == 0] <- NA
  
  output$plot3 <- renderPlot({
    p <-
      ggplot(df.with.ss4,
             aes(
               x = Wavelength,
               y = Q50,
               group = Class,
               fill = Class,
               color = Class
             )) +
      geom_point() +
      geom_ribbon(aes(ymin = Q25,  ymax = Q75),
                  alpha = .3,
                  linetype = 0) +
      xlab("Wavelength (nm)") +
      ylab("Radiance at sensor") +
      ggtitle("Trainer signatures - Q50 and IQR") +
      theme_bw()
    print(p)
  })
  
  
  ###############################################################################
  ### from here  is AI -- our training data is  "train.data"
  ## losely from https://github.com/zia207/Satellite-Images-Classification-with-H2O-R
  train.data$Class <- as.factor(train.data$Class)
  
  ### to make things faster I  select only 40 spectral bands... 288 are too many, getting close to overfitting - BUT
  ### I use to most important ones... which are they?
  # cols<-sample(1:length(bands.wavelengths.nm), 50)
  #  train.data2<-train.data[, c("Class", as.character(cols))]
  
  names(train.data) <- c("Class", names(myImage))
  localH2o <- h2o.init(nthreads = -1, max_mem_size = "50G")
  #### Import data to H2O cluster
  train <-  as.h2o(train.data)
  myImage.df<-NULL
  withProgress(message = "Elaborazione con Algoritmi di Intelligenza Artificiale",
               detail = "Converto immagine a matrice n2D...",
               value = 0,
               {
                 myImage.df<-as.data.frame(myImage)
                 
                 setProgress(value = 0.1 ,
                             detail = "Converto matrice a oggetto h2o...")
                 
                 grid <-  as.h2o(myImage.df)
                 #grid<- as.h2o(grid.data)
                 
                 #### Split data into train, validation and test dataset
                 # splits <- h2o.splitFrame(df, c(0.75,0.125), seed=1234)
                 # train  <- h2o.assign(splits[[1]], "train.hex") # 75%
                 # valid  <- h2o.assign(splits[[2]], "valid.hex") # 12%
                 # test   <- h2o.assign(splits[[3]], "test.hex")  # 13%
                 
                 
                 
                 y <- "Class"
                 x <- setdiff(names(train.data), y)
                 models <- list()
                 setProgress(value = 0.21 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["RF"]]))

                 models[["RF"]] <- h2o.randomForest(
                   x = x,
                   y = y,
                   ntrees = 10,
                   max_depth = 5,
                   min_rows = 10,
                   binomial_double_trees = TRUE,
                   training_frame = train
                 )

                 setProgress(value = 0.24 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["NB"]]))
                 models[["NB"]]  <- h2o.naiveBayes(
                   x = x,
                   y = y,
                   training_frame = train,
                   laplace = 0,
                   nfolds = 3,
                   seed = 1234
                 )

                 setProgress(value = 0.26 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["GMB"]]))
                 models[["GMB"]]  <- h2o.gbm(
                   x = x,
                   y = y,
                   training_frame = train,
                   ntrees = 10,
                   max_depth = 3,
                   min_rows = 2,
                   learn_rate = 0.2,
                   nfolds = 3,
                   keep_cross_validation_predictions = TRUE,
                   seed = 1
                 )
                 ## Deep Learning Model
                 setProgress(value = 0.28 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["DL"]]))
                 models[["DL"]]  <- h2o.deeplearning(
                   model_id = "Deep_Learning",
                   # Destination id for this model
                   training_frame = train,
                   # Id of the training data frame
                   #  validation_frame=valid,                    # Id of the validation data frame
                   x = x,
                   # a vector predictor variable
                   y = y,
                   # name of reponse vaiables
                   standardize = TRUE,
                   # standardize the data
                   score_training_samples = 0,
                   # training set samples for scoring (0 for all)
                   activation = "RectifierWithDropout",
                   # Activation function
                   score_each_iteration = TRUE,
                   hidden = c(200, 200, 200, 200),
                   # 4 hidden layers, each of 200 neurons
                   hidden_dropout_ratios = c(0.2, 0.1, 0.1, 0),
                   # for improve generalization
                   stopping_tolerance = 0.001,
                   # tolerance for metric-based stopping criterion
                   epochs = 100,
                   # the dataset should be iterated (streamed)
                   adaptive_rate = TRUE,
                   # manually tuned learning rate
                   l1 = 1e-6,
                   # L1/L2 regularization, improve generalization
                   l2 = 1e-6,
                   max_w2 = 10,
                   # helps stability for Rectifier
                   nfolds = 3,
                   # Number of folds for K-fold cross-validation
                   fold_assignment = "Stratified",
                   # Cross-validation fold assignment scheme
                   keep_cross_validation_fold_assignment = TRUE,
                   seed = 125,
                   reproducible = TRUE,
                   variable_importances = T
                 )

                 
                 rasters <- list()
                 for (i in names(models)) {
                   setProgress(
                     value = 0.3 + length(rasters) / 100 ,
                     detail = sprintf("Applico classificazione con modello %s", model.names[[i]])
                   )
                   g.predict = as.data.frame(h2o.predict(object = models[[i]], newdata = grid))
                   rasters[[i]] <-  raster(myImage)
                   rasters[[i]][]  <-
                     factor(g.predict$predict, levels = levels(train.data$Class))
                 }
                 
                 setProgress(value = 0.4, detail = "Creo grafico...")
                 rb <- raster::brick(rasters)
                 
                 
  
  
                models.rminer<-list()
                rasters.rminer<-list()
                  
  
                # setProgress(value = 0.42, message = "Utilizzo libreria RMINER...", detail=".....")
  
         
                 setProgress(value = 0.48 ,
                             detail = sprintf("Creo modello di classificazione con metodo %s.", model.names[[ "SVM" ]] ) )
 
                models.rminer[["SVM"]] <- rminer::fit(Class~.,data=train.data, task="class",  model="ksvm", feature="s") 
                
     
                setProgress(value = 0.5 ,
                             detail = sprintf("Applico classificazione con metodo '%s'.", model.names[[ "SVM" ]] ))
                         
             
    
                 rasters.rminer[[ model.names[[ "SVM" ]]  ]] <- predict(myImage,  models.rminer[["SVM"]] )
 
                 
                models.rminer[["RF"]] <- rminer::fit(Class~.,data=train.data, task="class",  model="randomForest") 
                
                
                 print("6")
 setProgress(value = 0.6 ,
                             detail = sprintf("Applico classificazione con metodo '%s'.", model.names[[ "RF" ]] ))
                rasters.rminer[[ model.names[[ "RF" ]]  ]] <-  raster::predict(myImage,  models.rminer[["RF"]] )
                
                
                 print("7")
                models.rminer[["KNN"]] <- rminer::fit(Class~.,data=train.data, task="class",  model="knn") 
                                
 setProgress(value = 0.7 ,
                             detail = sprintf("Applico classificazione con metodo '%s'.", model.names[[ "KNN" ]] ))
                rasters.rminer[[ model.names[[ "KNN" ]]    ]] <- raster::predict(  myImage, models.rminer[["KNN"]] )


                 print("8")
                 setProgress(value = 0.89, detail = "Creo grafico...")
                 

                 
               })
  
                 print("9")
                    rb.rminer <- raster::brick(rasters.rminer)
                  output$plot5 <- renderPlot({  levelplot(rb.rminer,  xlab = "X", ylab = "Y", main="Modelli da libreria rminer")  })
  
                 print("99")
                    lu <- levelplot(rb,  xlab = "X", ylab = "Y")
                  
                  output$plot4 <- renderPlot({  lu  })
                  
                 
})



```

&nbsp;



&nbsp;


&nbsp;
