---
title: "Giochi di Analisi Immagini Digitali"
author: "Francesco Pirotti - CIRGEO / TESAF  - Università di Padova"
date: "27/8/2020" 
output:
  html_notebook: 
    toc: yes
  html_document:
 # ioslides_presentation: 
    highlight: tango 
    toc_float:
      
      collapsed: no
      smooth_scroll: no
runtime: shiny
---
```{r, echo=FALSE}
shiny::addResourcePath("shinyjs", system.file("srcjs", package = "shinyjs"))
```
```{r, context="server"}
shinyjs::useShinyjs(html = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
```{css, echo=FALSE}
.irs-bar-edge, .irs-bar {
  display:none;
}
```
<!-- ## Shiny Presentation -->

<!-- The following single character keyboard shortcuts enable alternate display modes: -->

<!-- 'f': enable fullscreen mode  -->
<!-- 'w': toggle widescreen mode  -->
<!-- 'o': enable overview mode  -->
<!-- 'h': enable code highlight mode  -->
<!-- 'p': show presenter notes -->

<!-- Pressing Esc exits all of these modes -->

## Note introduttive

**Il codice in R di questo esercizio è disponibile in GitHub [QUI](https://github.com/fpirotti/HyperspectralGames){target=_blank}**


```{css}

* {box-sizing: border-box;}

.img-zoom-container {
  position: relative;
}

.img-zoom-lens {
  position: absolute;
  border: 0px solid #d4d4d4;
  /*set the size of the lens:*/
  width: 40px;
  height: 40px;
}

div.main-container{
  max-width:9000px !important;  
}

.img-zoom-result {
  border: 2px solid #d4d4d4;
  /*set the size of the result div:*/
  width: 220px;
  height: 220px;
}

```



 ```{js}
 var initialized = false;
 
 $('#plot1').on('DOMSubtreeModified', 'img', function(){
  console.log(this);
  
  imageZoom( this, "myresult" );
});

 function imageZoom(img, resultID) {
 
  var  lens, result, cx, cy;
  // img = document.getElementById(imgID).children[0];
  result = document.getElementById(resultID);
  
  /*create lens:*/
  lens = document.createElement("DIV");
  lens.setAttribute("class", "img-zoom-lens");
 
  /*insert lens:*/
  img.parentElement.insertBefore(lens, img);
  /*calculate the ratio between result DIV and lens:*/
  cx = result.offsetWidth / lens.offsetWidth;
  cy = result.offsetHeight / lens.offsetHeight;
  /*set background properties for the result DIV:*/
  result.style.backgroundImage = "url('" + img.src + "')";
  result.style.backgroundSize = (img.width * cx) + "px " + (img.height * cy) + "px";
  /*execute a function when someone moves the cursor over the image, or the lens:*/
  lens.addEventListener("mousemove", moveLens);
  img.addEventListener("mousemove", moveLens);
  /*and also for touch screens:*/
  lens.addEventListener("touchmove", moveLens);
  img.addEventListener("touchmove", moveLens);

  function moveLens(e) {
    var pos, x, y;
    /*prevent any other actions that may occur when moving over the image:*/
    e.preventDefault();
    /*get the cursor's x and y positions:*/
    pos = getCursorPos(e);
    /*calculate the position of the lens:*/
    x = pos.x - (lens.offsetWidth / 2);
    y = pos.y - (lens.offsetHeight / 2);
    /*prevent the lens from being positioned outside the image:*/
    if (x > img.width - lens.offsetWidth) {x = img.width - lens.offsetWidth;}
    if (x < 0) {x = 0;}
    if (y > img.height - lens.offsetHeight) {y = img.height - lens.offsetHeight;}
    if (y < 0) {y = 0;}
    /*set the position of the lens:*/
    lens.style.left = x + "px";
    lens.style.top = y + "px";
    /*display what the lens "sees":*/
    result.style.backgroundPosition = "-" + (x * cx) + "px -" + (y * cy) + "px";
  }
  function getCursorPos(e) {
    var a, x = 0, y = 0;
    e = e || window.event;
    /*get the x and y positions of the image:*/
    a = img.getBoundingClientRect();
    /*calculate the cursor's x and y coordinates, relative to the image:*/
    x = e.pageX - a.left;
    y = e.pageY - a.top;
    /*consider any page scrolling:*/
    x = x - window.pageXOffset;
    y = y - window.pageYOffset;
    return {x : x, y : y};
  }
}
 
 
 
 
``` 


```{r message=FALSE }

library(shinyWidgets)
library(raster)
library(rgdal) 
library(ggplot2) 
library(plotly)
library(readr) 
library(dplyr)
library(reshape2)
library(shinyjs)
library(rasterVis)
library(rasclass)
library(dygraphs)
library(h2o) ## A.I. library
useShinyjs(rmd = TRUE)

```

## Read the data

We read the two images that were previously cut (see file index.R which has some preprocessing steps). Hint - try to use rgdal package which is much faster than the raster package for many things.

```{r }

myImages<-list()

img.file<-"test/T32TQR_20180424_small.tif" 
# vnir.file2<-"/archivio/home/pirotti/Google Drive/RAD_3451-1_VNIR_1800_SN00852_22000us_2020-02-11T144756_raw_rad2.tif" 
  
myImage<-raster::brick(img.file, values=TRUE) 
 
# myImages[['VNIR2']]<-raster::brick(vnir.file2)
# 
 names(myImage)<- c( "490nm", "560nm", "665nm", "705nm", "740nm", "783nm", "842nm", "865nm", "1610nm", "2190nm" ) 
  
 

### here we extract wavelengths from the band names
bands.wavelengths.nm<-readr::parse_number(names(myImage)) 

### here we put them in a string with a suffix with the sensor name, we will use this later to populate sliders for choosing the band combinations to plot and RGB image.
bands<-names(myImage)


``` 

## Immagine Sentinel-2 L2A



```{r }
fluidRow(
  column(6, 
         shinyWidgets::sliderTextInput(
            "bandR",
            label = "Rosso",
            width = "100%",
            choices = bands,
            selected = bands[[3]]
          ),
         shinyWidgets::sliderTextInput(
            "bandG",
            label = "Verde",
            width = "100%",
            choices = bands ,
            selected = bands[[2]]
          ),
         shinyWidgets::sliderTextInput(
            "bandB",
            label = "Blue",
            width = "100%",
            choices = bands ,
            selected = bands[[1]]
          )    
    ),
  
  column( 6,    div( id="myresult", class="img-zoom-result" )  )
  
)
```
### Doppio click per singola firma spettrale - singolo click per aggiungerla

```{r }


fluidRow( 

  column( 6,    imageOutput("plot1", width = 672, height= 474,
    dblclick = "plot_dblclick", click = "plot_click" )   ),
  
  column( 6,    plotlyOutput("graph1") )
  
)
output$plot1 <- renderPlot({
  
  req(input$bandR, input$bandG, input$bandB)
   
  plotRGB(
    myImage,
    r = isolate({ which(input$bandR == bands) }),
    g = isolate({ which(input$bandG == bands) }),
    b = isolate({ which(input$bandB == bands) }), 
    stretch = "hist",
    main ="Clicca per firma spettrale pixel - doppio click per aggiungere"
  )
  
})






 

observeEvent(input$plot_dblclick, {
  
  req(input$plot_dblclick)
  values <- gdalUtils::gdallocationinfo(img.file, input$plot_dblclick$x,
                                input$plot_dblclick$y, geoloc=T, valonly = T)
 
  values.num <- as.numeric(values) 
  
  x.click <- as.integer(input$plot_dblclick$x)
  y.click <- as.integer(input$plot_dblclick$y)
  
  plotlyProxyInvoke(plotlyProxy("graph1", session), "addTraces", list(
    list(
      x = bands.wavelengths.nm,
      y = values.num,
      type = 'scatter',
      mode = 'markers+lines',  line = list(shape = "spline")
    )
    
  ))
  
})


output$graph1 <- renderPlotly({
  
  req(input$plot_click$x)
  #shinyjs::runjs( '  if(!initialized) imageZoom("plot1", "myresult")' );

  print(input$plot_click$x)
  values <- gdalUtils::gdallocationinfo(img.file, input$plot_click$x,
                                input$plot_click$y, geoloc=T, valonly = T)
 
  values.num <- as.numeric(values) 
  
  x.click <- as.integer(input$plot_click$x)
  y.click <- as.integer(input$plot_click$y)
  
  if (!shiny::isTruthy(x.click))
    x.click <- 0
  if (!shiny::isTruthy(y.click))
    y.click <- "0 - click image above."
  
  p <- plot_ly(type = "scatter", mode = "markers") %>% layout( 
    xaxis = list(title = "Wavelength (nm)"),
    yaxis = list(title = "Radiance at sensor ( ~reflectance )"),
    title = sprintf("Spectral signature at X=%s Y=%s",
                    x.click, y.click)
  ) %>% add_trace(
      y = values.num,
      x =  bands.wavelengths.nm,
      mode = "markers+lines",  line = list(shape = "spline")
  ) # %>% add_lines(  x =  bands.wavelengths.nm, y =values.num,   line = list(shape = "spline") )
  
  p
  
})

model.names <- list(RF = "Random Forest",
                    NB = "Naive Bayes",
                    GMB = "GMB",
                    DL = "Deep Learning")
```

## OK let's classify!

We will use only the SWIR because it is a lighter image and takes less time to process in real time and we do not want to be bored waiting for image to classify.

1. Grab some training pixels by choosing the class and start clicking on the image below.
2. Click **PLOT** if you want to redraw the points that were clicked (image is NOT auto-updated)
3. Once finished **clic "RUN"** to start training/validation/testing phase of the following models:
 ```{r  } 
 print(model.names)
 ```
 4. You will see a plot of signatures AND classified images



```{r  }


react <- reactiveValues(train.table = data.frame(
  id = integer(0),
  x = integer(0) ,
  y = integer(0),
  Class = character(0)
))

if (file.exists("s2.train.table.rds")) {
  react$train.table <-
    readRDS("s2.train.table.rds")
  
}

fluidRow(column(width = 12, shinyWidgets::addSpinner(
  plotOutput("plot2", click = "plot_click2")
)))


fluidRow(
  column(
    width = 4,
    radioGroupButtons(
      inputId = "myClass",
      label = "Scegli la classe per ROI",
      choices =  c("Urbano", "Acqua", "Vegetazione", "Agricolo", "Altro"),
      # justified = TRUE,
      direction = "vertical",
      checkIcon = list(yes = icon("ok",
                                  lib = "glyphicon"))
    )
  ),
  
  column(
    width = 5,
    div(style = "height:200px; overflow-y:auto;",  tableOutput("trainingTable"))
  ),
  
  column(
    width = 3,
    shiny::actionButton("plotTrain", label = "Disegna", shiny::icon("pen")),
    div(
      title = "Removes all points!!",
      shiny::actionButton("resetTrain", label = "RESET", shiny::icon("trash"))
    ),
    shiny::actionButton("runTrain",  label = "Elabora", shiny::icon("gear"))
  )
)

 

output$plot2 <- renderPlot({
  req(input$plotTrain)
  
  req(input$bandR, input$bandG, input$bandB)
   
  plotRGB(
    myImage,
    r = which(input$bandR == bands),
    g = which(input$bandG == bands),
    b = which(input$bandB == bands),
    scale = 255,
    stretch = "hist"
  )
  
  isolate({
    if (shiny::isTruthy(react$train.table) && nrow(react$train.table)) {
      col <- RColorBrewer::brewer.pal(6, "Paired")
      col2 <- RColorBrewer::brewer.pal(6, "Pastel2")
      train.table.classes <- as.factor(react$train.table$Class)
      
      points(
        react$train.table$x,
        react$train.table$y,
        col = col[train.table.classes],
        bg = col2[train.table.classes],
        pch = 21
      )
      
      text(
        react$train.table$x,
        react$train.table$y,
        pos = 2,
        react$train.table$id,
        col = col[train.table.classes]
      )
      
    }
  })
  
})


output$trainingTable <- renderTable({
  react$train.table
})

observeEvent(input$resetTrain,  {
  isolate({
    react$train.table <-
      data.frame(
        id = integer(0),
        x = integer(0) ,
        y = integer(0),
        Class = character(0)
      )
  })
})

observeEvent(input$plot_click2,  {
  isolate({
    react$train.table <-
      rbind(
        react$train.table,
        list(
          id = as.integer(nrow(react$train.table) + 1),
          x = as.integer(input$plot_click2$x),
          y = as.integer(input$plot_click2$y),
          Class = input$myClass
        )
      )
  })
})



fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot3"))))

fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot4"))))


observeEvent(input$runTrain, {
  
  req(input$runTrain, react$train.table)
  
  saveRDS(react$train.table, "s2.train.table.rds")
  
  if (nrow(react$train.table) < 10) {
    shinyWidgets::alert("Almeno 10 punti di ROI per classe", status =
                          "warning")
    shinyjs::alert("Almeno 10 punti di ROI per classe")
    return(NULL)
  }
  
  
  if (sum(table(react$train.table$Class) < 10) != 0) {
    whi <-
      paste0(collapse = ", ", names(which( table(
        react$train.table$Class
      ) < 10)))
    shinyWidgets::alert(
      sprintf(
        "Almeno 10 punti di ROI per classe.",
        whi
      ),
      status = "warning"
    )
    shinyjs::alert(sprintf(
      "Almeno 10 punti di ROI per classe! Classe/i %s hanno pochi punti ROI.",
      whi
    ))
    return(NULL)
  }
  
  ss <-
    matrix(
      data = NA,
      nrow = nrow(react$train.table),
      ncol = length( bands.wavelengths.nm)
    )
  
  withProgress(
    message = "Getting signatures",
    detail = sprintf("%s trainers", nrow(react$train.table)),
    value = 0,
    min = 0,
    max = nrow(react$train.table),
    {
      for (i in 1:nrow(react$train.table)) {
        setProgress(as.integer(i))
        ss[i,] <-
          as.numeric(
            gdalUtils::gdallocationinfo(
              img.file, geoloc=T, 
              react$train.table[i, "x"]  ,
              react$train.table[i, "y"],
              valonly = T
            )
          )
      }
    }
  )
  
  if (is.null(ss)) {
    shinyjs::alert("ISNULL!")
    return(NULL)
  }
  
  train.data <-
    as.data.frame(cbind(react$train.table[c("Class")], ss))
  
  ###############################################################################
  ### from here  is only for plotting - our training data is  "train.data"
  quants <- c(0.1, 0.25, 0.5, 0.75, 0.9)
  df.with.ss2 <-
    train.data  %>%  dplyr::group_by(Class) %>% dplyr::summarize_all(function(x) {
      if (is.numeric(x))
        quantile(as.numeric(x), quants)
      else
        c(0, 0, 0, 0, 0)
    })
  
  df.with.ss2$Quantile <-
    rep(sprintf("Q%s", quants * 100), length(unique(df.with.ss2$Class)))
  #saveRDS(as.data.frame(df.with.ss2), "df.with.ss2.rds")
  
  df.with.ss3 <- reshape2::melt(df.with.ss2)
  df.with.ss4 <-
    reshape2::dcast(df.with.ss3 ,   Class + variable ~ Quantile)
  df.with.ss4$Wavelength <-
    swir.bands.wavelengths[df.with.ss4$variable]
  df.with.ss4[df.with.ss4 == 0] <- NA
  
  output$plot3 <- renderPlot({
    p <-
      ggplot(df.with.ss4,
             aes(
               x = Wavelength,
               y = Q50,
               group = Class,
               fill = Class,
               color = Class
             )) +
      geom_point() +
      geom_ribbon(aes(ymin = Q25,  ymax = Q75),
                  alpha = .3,
                  linetype = 0) +
      xlab("Wavelength (nm)") +
      ylab("Radiance at sensor") +
      ggtitle("Trainer signatures - Q50 and IQR") +
      theme_bw()
    print(p)
  })
  
  
  ###############################################################################
  ### from here  is AI -- our training data is  "train.data"
  ## losely from https://github.com/zia207/Satellite-Images-Classification-with-H2O-R
  train.data$Class <- as.factor(train.data$Class)
  
  ### to make things faster I  select only 40 spectral bands... 288 are too many, getting close to overfitting - BUT
  ### I use to most important ones... which are they?
  # cols<-sample(1:length(swir.bands.wavelengths), 50)
  #  train.data2<-train.data[, c("Class", as.character(cols))]
  
  names(train.data) <- c("Class", names(myImages$SWIR))
  localH2o <- h2o.init(nthreads = 10, max_mem_size = "50G")
  #### Import data to H2O cluster
  train <-  as.h2o(train.data)
  
  withProgress(message = "Intelligence going Artificial",
               detail = "Converting image to matrix cube",
               value = 0,
               {
                 grid <-  as.h2o(as.data.frame(myImages$SWIR))
                 #grid<- as.h2o(grid.data)
                 
                 #### Split data into train, validation and test dataset
                 # splits <- h2o.splitFrame(df, c(0.75,0.125), seed=1234)
                 # train  <- h2o.assign(splits[[1]], "train.hex") # 75%
                 # valid  <- h2o.assign(splits[[2]], "valid.hex") # 12%
                 # test   <- h2o.assign(splits[[3]], "test.hex")  # 13%
                 
                 
                 
                 y <- "Class"
                 x <- setdiff(names(train.data), y)
                 models <- list()
                 setProgress(value = 0.21 ,
                             detail = sprintf("Defining model with '%s'.", model.names[["RF"]]))
                 
                 models[["RF"]] <- h2o.randomForest(
                   x = x,
                   y = y,
                   ntrees = 10,
                   max_depth = 5,
                   min_rows = 10,
                   binomial_double_trees = TRUE,
                   training_frame = train
                 )
                 
                 setProgress(value = 0.24 ,
                             detail = sprintf("Defining model with '%s'.", model.names[["NB"]]))
                 models[["NB"]]  <- h2o.naiveBayes(
                   x = x,
                   y = y,
                   training_frame = train,
                   laplace = 0,
                   nfolds = 3,
                   seed = 1234
                 )
                 
                 setProgress(value = 0.26 ,
                             detail = sprintf("Defining model with '%s'.", model.names[["GMB"]]))
                 models[["GMB"]]  <- h2o.gbm(
                   x = x,
                   y = y,
                   training_frame = train,
                   ntrees = 10,
                   max_depth = 3,
                   min_rows = 2,
                   learn_rate = 0.2,
                   nfolds = 3,
                   keep_cross_validation_predictions = TRUE,
                   seed = 1
                 )
                 ### Deep Learning Model
                 setProgress(value = 0.28 ,
                             detail = sprintf("Defining model with '%s'.", model.names[["DL"]]))
                 models[["DL"]]  <- h2o.deeplearning(
                   model_id = "Deep_Learning",
                   # Destination id for this model
                   training_frame = train,
                   # Id of the training data frame
                   #  validation_frame=valid,                    # Id of the validation data frame
                   x = x,
                   # a vector predictor variable
                   y = y,
                   # name of reponse vaiables
                   standardize = TRUE,
                   # standardize the data
                   score_training_samples = 0,
                   # training set samples for scoring (0 for all)
                   activation = "RectifierWithDropout",
                   # Activation function
                   score_each_iteration = TRUE,
                   hidden = c(200, 200, 200, 200),
                   # 4 hidden layers, each of 200 neurons
                   hidden_dropout_ratios = c(0.2, 0.1, 0.1, 0),
                   # for improve generalization
                   stopping_tolerance = 0.001,
                   # tolerance for metric-based stopping criterion
                   epochs = 100,
                   # the dataset should be iterated (streamed)
                   adaptive_rate = TRUE,
                   # manually tuned learning rate
                   l1 = 1e-6,
                   # L1/L2 regularization, improve generalization
                   l2 = 1e-6,
                   max_w2 = 10,
                   # helps stability for Rectifier
                   nfolds = 3,
                   # Number of folds for K-fold cross-validation
                   fold_assignment = "Stratified",
                   # Cross-validation fold assignment scheme
                   keep_cross_validation_fold_assignment = TRUE,
                   seed = 125,
                   reproducible = TRUE,
                   variable_importances = T
                 )
                 
                 
                 rasters <- list()
                 for (i in names(models)) {
                   setProgress(
                     value = 0.5 + length(rasters) / 10 ,
                     detail = sprintf("Predicting with %s", model.names[[i]])
                   )
                   g.predict = as.data.frame(h2o.predict(object = models[[i]], newdata = grid))
                   rasters[[i]] <-  raster(myImages$SWIR)
                   rasters[[i]][]  <-
                     factor(g.predict$predict, levels = levels(train.data$Class))
                 }
                 
                 setProgress(value = 0.99, detail = "Stacking results")
                 rb <- raster::brick(rasters)
                 
                 
               })
  
  
  lu <- levelplot(rb,  xlab = "X", ylab = "Y")
  
  output$plot4 <- renderPlot({
    lu
  })
  
})
```

&nbsp;



&nbsp;


&nbsp;
