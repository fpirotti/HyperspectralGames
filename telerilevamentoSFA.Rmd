---
title: "Analizzare Immagini Digitali: dalla Visualizzazione all'Intelligenza Artificiale"
author: "Francesco Pirotti - CIRGEO / TESAF  - Università di Padova"
date: "27/8/2020" 
output:
  html_notebook: 
    toc_float: yes
  html_document:
 # ioslides_presentation: 
    highlight: tango 
    toc_float:
      
      collapsed: no
      smooth_scroll: no
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE )
```

```{r, echo=FALSE}
shiny::addResourcePath("shinyjs", system.file("srcjs", package = "shinyjs"))
```
```{r, context="server"}
shinyjs::useShinyjs(html = TRUE)
```


```{css, echo=FALSE}
.irs-bar-edge, .irs-bar {
  display:none;
}
  
#coordinate {
    height: 36px;
    margin: 0;
    margin-top: 24px;
    padding: 4px;
}

* {box-sizing: border-box;}

.shiny-notification {
              height: 200px;
              width: 800px;
              position:fixed;
              top: calc(50% - 50px);;
              left: calc(50% - 400px);;
            }
.img-zoom-container {
  position: relative;
}

.img-zoom-lens {
  pointer-events: none;
  position: absolute;
  border: 2px solid red; 
  z-index:99999; 
}

div.main-container{
  max-width:9000px !important;  
}
#plot1 {
 position: relative;
}
.img-zoom-result {
  position:absolute;
  background-repeat:space;
  border: 2px solid rgb(255, 0 ,0); 
  width: 160px;
  height: 160px;
  z-index:99999; 
  visibility:hidden;
}

.img-zoom-result-inner {   
  border: 2px solid rgb(255, 0 ,0); 
  width: 10px;
  height: 10px;
  margin:75px auto;
  z-index:99999;
}
```


```{js}
 var initialized = false;
 var  lens, lens2, result, cx, cy, lenszoom, img;
 lenszoom=0;
  
$( document ).ready(function() {
 
//  $( "div[ data-value='firme.panel']" ).css({ 'padding':'3px', 'background':'rgba(200,0,0,0.1)'  });
//    $( "a[ data-value='firme.panel']" ).parent().css({ 'background':'rgba(200,0,0,0.1)' });
//  
//  
//  $( "div[ data-value='classificazione.panel']" ).css({ 'padding':'3px', 'background':'rgba(200,200,0,0.1)'  // });
//    $( "a[ data-value='classificazione.panel']" ).parent().css({ 'background':'rgba(200,200,0,0.1)' });
//    
//  $( "div[ data-value='indici.panel']" ).css({ 'padding':'3px', 'background':'rgba(200,0,200,0.1)'  });
//    $( "a[ data-value='indici.panel']" ).parent().css({ 'background':'rgba(200,0,200,0.1)' });
   
});

  
  
 $('#plot1').on('DOMSubtreeModified', 'img', function(){
  imageZoom( this, "myresult", true );
  });

  
    function enterImg(e) { result.style.visibility="visible";  lens.style.visibility="visible";  }
    function exitImg(e) { result.style.visibility="hidden";    lens.style.visibility="hidden"; }

    function moveLens(e) {
    
      var pos, x, y;
      /*prevent any other actions that may occur when moving over the image:*/
      e.preventDefault();
      /*get the cursor's x and y positions:*/
      pos = getCursorPos(e);
      /*calculate the position of the lens:*/
      x = pos.x - (lens.offsetWidth / 2);
      y = pos.y - (lens.offsetHeight / 2);
   
 
      lens.style.left = x + "px";
      lens.style.top = y + "px";
      
      result.style.left = (x + lens.offsetWidth) + "px";
      result.style.top = y + "px";
      
      /*display what the lens "sees":*/
      result.style.backgroundPosition =   (-1*x * cx) + "px " + (-1*y * cy) + "px";
    }
    
    function getCursorPos(e) {
      var a, x = 0, y = 0;
      e = e || window.event;
      /*get the x and y positions of the image:*/
      a = img.getBoundingClientRect();
      /*calculate the cursor's x and y coordinates, relative to the image:*/
      x = e.pageX - a.left;
      y = e.pageY - a.top;
      /*consider any page scrolling:*/
      x = x - window.pageXOffset;
      y = y - window.pageYOffset;
      return {x : x, y : y};
    }
      

 function imageZoom(img2, resultID, domreload=false) {
  
    // img = document.getElementById(imgID).children[0];
    result = document.getElementById(resultID); 
    /*create lens:*/
    if( $(".img-zoom-lens").length == 0) {
      lens = document.createElement("DIV");
      lens.setAttribute("class", "img-zoom-lens"); 
     
      lens.style.height= (result.offsetWidth / lenszoom)+"px";
      lens.style.width= (result.offsetHeight / lenszoom)+"px";
      img2.parentElement.parentElement.insertBefore(lens, img2.parentElement);
    } else {
      lens.style.height= (result.offsetWidth / lenszoom)+"px";
      lens.style.width= (result.offsetHeight / lenszoom)+"px"; 
    }
         /*calculate the ratio between result DIV and lens:*/
    cx = result.offsetWidth / lens.offsetWidth;
    cy = result.offsetHeight / lens.offsetHeight;
      /*execute a function when someone moves the cursor over the image, or the lens:*/
   // lens.addEventListener("mousemove", moveLens);
     img2.removeEventListener("mousemove",moveLens);
     img2.removeEventListener("mouseenter",enterImg);
     img2.removeEventListener("mouseout",exitImg);
     img2.removeEventListener("touchmove",moveLens);
     if(lenszoom!=0){
        img2.addEventListener("mousemove", moveLens); 
        img2.addEventListener("mouseenter", enterImg); 
        img2.addEventListener("touchmove", moveLens);
     }
    img2.addEventListener("mouseout", exitImg);  
 
    
    /*set background properties for the result DIV:*/
   if(domreload) $(result).css({ 'background-color':'white', 'background-image' : 'url(' + img2.src + ')'  });
    //result.style.backgroundImage = "url('" + img.src + "')";
//    result.style.background = "white";
    result.style.backgroundSize = (img2.width * cx) + "px " + (img2.height * cy) + "px";
    
    img=img2;
    
  
}
 
 
 
 
``` 


```{r message=FALSE }

library(shinyWidgets)
library(raster)
library(rgdal) 
library(ggplot2) 
library(plotly)
library(readr) 
library(dplyr)
library(reshape2)
library(shinyjs)
library(rasterVis)
library(rasclass)
library(dygraphs)
library(h2o) ## A.I. library
useShinyjs(rmd = TRUE)
 
s2.bands<-readRDS("s2.bands.rds")
band.colors<-c("#680085", "#0036ff", "#09ff00", "#ed0000", "#e70000", "#e70000", 
               "#e70000", "#e70000", "#a20000", "#a20000","#a20000", "#500000", "#500000")
#s2.bands<-s2.bands[-11,]
rectangles<-apply(s2.bands, 1, function(x){ 
  list(
    
    type = "rect",
    fillcolor = band.colors[[ as.integer(x[[1]]) ]],
    line = list(color = band.colors[[ as.integer(x[[1]]) ]] ),
    opacity = 0.4,
    x0 =  as.integer(x[['min.wl']]),
    x1 =  as.integer(x[['max.wl']]),
    xref = "x",
    y0 = 0,
    y1 = 0.7,
    yref = "y",
    name = x[['desc.ita']]
    
  )
} )


lang="ITA"

Sentinel.classification = list(
"ff0004"= list("ENG"="Saturated or defective",  
               "ITA"="Saturo o difettoso" ),
"868686"= list("ENG"="Dark Area Pixels", 
               "ITA"="Area nera"),
"774b0a"= list("ENG"="Cloud Shadows", 
               "ITA"="Ombra nuvole"),
"10d22c"= list("ENG"="Vegetation", 
               "ITA"="Vegetazione"),
"ffff52"= list("ENG"="Bare Soils", 
               "ITA"="Suolo nudo"),
"0000ff"= list("ENG"="Water", 
               "ITA"="Acqua"),
"818181"= list("ENG"="Clouds Low Probability / Unclassified", 
               "ITA"="Nuvole (bassa prob.) / non classificato"),
"c0c0c0"= list("ENG"="Clouds Medium Probability", 
               "ITA"="Nuvole (media prob.)"),
"f1f1f1"= list("ENG"="Clouds High Probability", 
               "ITA"="Nuvole (alta prob.)"),
"bac5eb"= list("ENG"="Cirrus", 
               "ITA"="Cirrus"),
"52fff9"= list("ENG"="Snow / Ice", 
               "ITA"="Neve/ghiaccio")
)

translations<-list(
  "precaricati"=list("ENG"="Predefined", "ITA"="Precaricati"),
  "r"=list("ENG"="Red", "ITA"="Rosso"),
  "g"=list("ENG"="Green", "ITA"="Verde"),
  "b"=list("ENG"="Blue", "ITA"="Blu"),
  "firme.spettrali"=list("ENG"="Spectral Signatures", "ITA"="Firme Spettrali"),
  "firme.spettrali.cancella"=list("ENG"="Remove Signatures", "ITA"="Cancella Firme"),
  "firme.spettrali.x"=list("ENG"="Wavelength (nm)", "ITA"="Lunghezza d'onda (nm)"),
  "firme.spettrali.y"=list("ENG"="BOA (Bottom of Atmosphere) Reflectance", "ITA"="Riflettanza BOA"),
  "index.fomula.wrong"=list("ENG"= "Cannot understand index formula - use standard mathematical operators and band alias names (B1, B2, B8A etc...)", 
                            "ITA"= "Formula dell'indice non comprensibile - utilizza operatori matematici standard ed i nomi delle bande (B1, B2, B8A ecc...)")
)


myImages<-list( "Padova" = list(file="test/T32TQR_20180424_spectral.tif", type="S2" ),
                "Padova" = list(file="test/T32TQR_20180424_spectral.tif", type="S2"  ) )


img.file<-"test/T32TQR_20180424_spectral.tif" 
class.file<-"test/T32TQR_20180424_Class.tif" 
# vnir.file2<-"/archivio/home/pirotti/Google Drive/RAD_3451-1_VNIR_1800_SN00852_22000us_2020-02-11T144756_raw_rad2.tif" 
  
myImage<-raster::brick(img.file, values=TRUE) 

myImage.class<-    raster::raster(class.file) 
uv<-  unique(myImage.class[])
r <- data.frame(ID=uv, 
                name=sapply(Sentinel.classification[uv], function(x){ x[[lang]] }) )
levels(myImage.class)[[1]]<-r
 
myTheme <- rasterTheme(region = sprintf("#%s", toupper(names(Sentinel.classification)[uv]) ) )

bands.alias<-c("B1",  "B2", "B3", "B4","B5", "B6","B7", "B8","B8A", "B9", "B11", "B12")
bands.wavelengths.nm <-c(442 , 490, 560, 665, 705, 740, 783, 842, 864, 945, 1610, 2190 ) 

bands.wavelengths.char<-sprintf("%snm", bands.wavelengths.nm ) 
bands.resolution<-c("60m",  "10m", "10m", "10m","20m", "20m","20m", "10m","20m","60m",  "20m", "20m")
names(myImage)<- bands.alias
  
### here we extract wavelengths from the band names
# bands.wavelengths.nm<-readr::parse_number(bands.wavelengths.char) 

### here we put them in a string with a suffix with the sensor name, we will use this later to populate sliders for choosing the band combinations to plot and RGB image.
bands.picker<-bands.alias

bands.picker.content <-  sprintf( "%s-%s (%s)", bands.alias, bands.wavelengths.char, bands.resolution )
#names(bands.picker.content) <-   bands.wavelengths.char
names(bands.picker)<-  bands.picker.content #sprintf( "%s - %s (%s)", bands.alias, bands.wavelengths.char, bands.resolution )

bands.picker<-list("Visibile"=bands.picker[1:4], 
                   "NIR/Red Edge"=bands.picker[5:9],
                   "Cirrus"=bands.picker[10],
                   "SWIR"=bands.picker[11:12] )

``` 

## Note introduttive

**Il codice in R di questo esercizio è disponibile in GitHub [QUI](https://github.com/fpirotti/HyperspectralGames){target=_blank}**

Nelle sezioni seguenti vedrete un ritaglio di un'immagine  Sentinel-2 L2A ripresa sopra la città di Padova il giorno 24 aprile 2018 (noterete facilmente in alto a destra Prato della Valle). Sono riportate solo le [bande a 10 m e 20 m del sensore Sentinel 2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR#bands){target=_blank}.

Ogni sezione consente di interagire con l'immagine per analizzarne alcuni aspetti:

- La visualizzazione a schermo assegnando combinazioni di [**bande**](https://it.wikipedia.org/wiki/Spettro_elettromagnetico#Suddivisione_in_bande){target=_blank} dello [**spettro elettromagnetico**](https://it.wikipedia.org/wiki/Spettro_elettromagnetico){target=_blank} ai tre canali. 
- La [**firma spettrale**](https://it.wikipedia.org/wiki/Firma_spettrale){target=_blank} su un punto selezionato
- L'applicazione di operazioni tra bande per creare degli **indicatori** (e.g. [NDVI](https://it.wikipedia.org/wiki/Normalized_Difference_Vegetation_Index){target=_blank}) che aiutano l'interpretazione di alcuni fenomeni. 
- Le operazioni per la **classificazione supervisionata** (i.e. con il supporto dell'operatore):
  - La definizione di punti sull'immagine per l'addestramento del modello  (punti definiti anche **ROI/POI** - regions/points of interest, regioni/punti di interesse)
  - La creazione di **modelli predittivi** usanto i dati di addestramento/training con:
    - metodi classici ( __Maximum Likelyhood__, __Spectral Angle Mapper__, __Minimum Distance__)
    - metodi di A.I. - __machine learning__  (Random Forest, Support Vector Machine)
    - metodi di A.I. - __deep learning__ (reti neurali multi-strato...)
- Le operazioni di **analisi dell'accuratezza stimata** mediante [matrici di confusione](https://it.wikipedia.org/wiki/Matrice_di_confusione){target=_blank} e la creazione di **indici di accuratezza** per classe e totali (indice [__Kappa__](https://it.wikipedia.org/wiki/Kappa_di_Cohen){target=_blank}, [__ROC__](https://it.wikipedia.org/wiki/Receiver_operating_characteristic){target=_blank}, [__precisione/recupero__](https://it.wikipedia.org/wiki/Precisione_e_recupero){target=_blank}, [__falsi positivi__](https://it.wikipedia.org/wiki/Falso_positivo){target=_blank},  [__falsi negativi__](https://it.wikipedia.org/wiki/Falso_negativo){target=_blank}, [__F1-score__](https://it.wikipedia.org/wiki/F1_score){target=_blank}, etc...)


All'inizio di ogni sezione viene proposto un esercizio che potete eseguire con l'interfaccia.




## Visualizzazione e Firme spettrali

- Scegli dal menù a tendina quali bande assegnare ai 3 canali di colore dell schermo (RGB) - e.g. 
- **Singolo click** - usa il puntatore sull'immagine per aggiungere una firma spettrale di un determinato pixel.
- **Doppio click** - usa il puntatore sull'immagine cliccando duo volte per aggiungere un POI .

```{r }
 
react <- reactiveValues(train.table = data.frame(
  id = integer(0),
  x = integer(0) ,
  y = integer(0),
  Class = character(0)
))


img.file.sigs<-img.file
raster::extension(img.file.sigs)<-"rds"

if (file.exists(img.file.sigs)) {
  react$train.table <-
    readRDS(img.file.sigs)
  
  #saveRDS(img.file.sigs, img.file.sigs)

}


fluidRow(
  column(
    6,
    style = "margin:0; margin-bottom:10px; margin-left:5px; padding:0; width:620px !important;",
    
    div(style = "margin:0; display:flex; gap: 5px;   width:680px !important;", ),
    ## https://www.indexdatabase.de/db/s-single.php?id=96
    div(
      style = "margin:0; display:flex; gap: 5px;   width:680px !important;",
      shinyWidgets::pickerInput(
        "colorChoose",
        translations$precaricati[[lang]],
        width = 240,
        choices = list(
          "Colori Naturali (B4, B3, B2)" = "B4, B3, B2",
          "Colori NIR (B8, B4, B3)" =
            "B8, B4, B3",
          "SW IR (B12, B8A, B4)" = "B12, B8A, B4",
          "Geologia (B12, B11, B2)" =
            "B12, B11, B2",
          "Batimetria (B4, B3, B1)" =
            "B4, B3, B1",
          "Agricoltura (B11, B8, B2)" =
            "B11, B8, B2"
        )
      ),
      
      radioGroupButtons(
        inputId = "zoomLens",
        width = 220,
        label = "Ingrandimento Lente",
        choices = c(
          `<i class='fa fa-ban'></i>` = "0",
          `<i class='fa fa-search'></i> x2` = "2",
          `<i class='fa fa-search'></i> x4` = "4",
          `<i class='fa fa-search'></i> x8` = "8"
        ),
        justified = TRUE
      ),
      verbatimTextOutput("coordinate")
    ),
    
    div(
      style = "margin:0; display:flex; gap: 5px; ",
      shinyWidgets::pickerInput(
        "bandR",
        label = "Rosso",
        width = 180,
        choices = bands.picker,
        selected = bands.picker[[1]][[4]]
      ),
      shinyWidgets::pickerInput(
        "bandG",
        label = "Verde",
        width = 180,
        choices = bands.picker ,
        selected = bands.picker[[1]][[3]]
      ),
      shinyWidgets::pickerInput(
        "bandB",
        label = "Blue",
        width = 180,
        choices = bands.picker ,
        selected = bands.picker[[1]][[2]]
      )
    ),
    
    div(
      style = "position:relative;",
      div(
        id = "myresult",
        class = "img-zoom-result",
        div(class = "img-zoom-result-inner")
      ),
      imageOutput(
        "plot1",
        width = ncol(myImage),
        height = nrow(myImage),
        dblclick = "plot_dblclick",
        hover = "plot_hover",
        click = "plot_click"
      )
    )
  ),
  
  
  
  column(
    6,
    style = "margin:0;  !important;  min-width:650px !important; margin-bottom:10px;",
    tabsetPanel(
      id = "pannelli",
      tabPanel(
        "Firme Spettrali",
        value = "firme.panel",
        shinyWidgets::actionBttn(
          inputId = "resetGraph",
          label = translations$firme.spettrali.cancella[[lang]] ,
          icon =  icon("trash"),
          color = "danger",
          style = "fill",
          size = "sm"
        ),
        plotlyOutput("graph1" , height = 500)
      ),
      tabPanel(
        "Indici",
        value = "indici.panel",
        fluidRow(
          column(5,  style = "margin:0;margin-top:5px;",    shiny::textInput("indexIn", "Formula")),
          column(
            7,
            style = "margin:0; display:flex; gap:5px; margin-top:5px;",
            shinyWidgets::pickerInput(
              "indexChoose",
              width = 200,
              translations$precaricati[[lang]],
              choices = list(
                "",
                "Aerosol free vegetation index 1600" =
                  "B9-0.66*B11/(B9+0.6611)",
                "Aerosol free vegetation index 2100" =
                  "B9-0.5*B12/(B9+0.5612)",
                "Atmospherically Resistant Vegetation Index 2" =
                  "-0.18+1.17*(B9-B5)/(B9+B5)",
                "NDVI" =
                  "(B8A-B4)/(B8A+B4)"
              )
            ),
            div(
              style = "  margin-top:25px;",
              title = "Calcola e disegna",
              shinyWidgets::actionBttn(
                inputId = "indexGo",
                label = NULL,
                icon =
                  icon("pencil"),
                color = "success",
                style = "fill",
                size = "sm"
              )
            ),
            div(
              style = "  margin-top:25px;",
              title = "Scarica un geotiff",
              shiny::downloadButton("indexDownload",
                                    label = NULL)
            )
          )
        ),
        shinyWidgets::addSpinner(imageOutput(
          "indexPlot",
          width = ncol(myImage) + 80,
          height = nrow(myImage) + 40
        ))
      ),
      tabPanel("Classificazione",   value = "classificazione.panel",
               
               fluidRow(
                 column(
                   width = 6,
                   # radioGroupButtons(
                   #   inputId = "myClass",
                   #   label = "Scegli la classe per ROI",
                   #   choices =  c("Urbano", "Acqua", "Vegetazione", "Agricolo", "Altro"),
                   #   # justified = TRUE,
                   #   direction = "vertical",
                   #   checkIcon = list(yes = icon("ok",
                   #                    lib = "glyphicon")
                   #                    )
                   #   ),
                   
                   selectizeInput(
                     "myClass",
                     "Aggiungi/scegli classe POI",
                     c(),
                     selected = NULL,
                     multiple = F,
                     options = list(create = TRUE)
                   ),
                   
                   div( 
                     shinyWidgets::actionBttn(
                       "plotTrain",
                       label = "RiDisegna",
                       size = "sm",
                       block = F,
                       style = "fill",
                       shiny::icon("pen")
                     )
                   ),
                   div( 
                     shinyWidgets::actionBttn(
                       "saveTrain",
                       label = "Salva",
                       size = "sm",
                       block = F,
                       style = "fill",
                       shiny::icon("save")
                     )
                   ),
                   div( 
                     title = "Removes all points!!",
                     shinyWidgets::actionBttn(
                       "resetTrain",
                       label = "RESET",
                       size = "sm",
                       block = F,
                       style = "fill",
                       shiny::icon("trash")
                     )
                   )
                 ),
                 
                 column(
                   width = 6,
                   div(style = "height:474px; overflow-y:auto;", DT::dataTableOutput("trainingTable") )
                 )
                 
               ))
    )
  )
  
)

### zoom LENTI
shiny::observeEvent(input$zoomLens, {
  req(input$zoomLens)
  shinyjs::runjs(
    sprintf(
      "lenszoom=%s; if($('#plot1 img').length==1) imageZoom( $('#plot1 img').get(0), \"myresult\", false );  ",
      input$zoomLens,
      input$zoomLens
    )
  )
}, ignoreInit = T)


#### INDEX DOWNLOAD ------
output$indexDownload <- downloadHandler(
    
    filename = function() {
      paste(tempfile(), ".tif", sep = "")
    },
    content = function(file) {
      eq <- gsub("B([1-9A]{1,2})", "myImage[['B\\1']]", input$indexIn)
      
      out.raster <- tryCatch( eval(parse(text = eq)), 
                            error = function(e) { e })  
    
      if( is.element("error", class(out.raster)) ){
        runjs(sprintf("alert(\"%s\");", translations$index.fomula.wrong[[lang]] ) )
        return(NULL)
      }
      ##write.csv(iris, file, row.names = FALSE)
    
      raster::writeRaster(out.raster, file, format="GTiff")
    }
  )

#### CALCOLA INDICE ###############
shiny::observeEvent(input$indexGo, {
  req(input$indexIn, input$indexGo)
  eq <- gsub("B([1-9A]{1,2})", "myImage[['B\\1']]", input$indexIn)
  
  out.raster <- tryCatch( eval(parse(text = eq)), 
                        error = function(e) { e })  

  if( is.element("error", class(out.raster)) ){
    runjs(sprintf("alert(\"%s\");", translations$index.fomula.wrong[[lang]] ) )
    return(NULL)
  }
  output$indexPlot <-
    renderPlot({
      rasterVis::levelplot(
        out.raster,
        par.settings = RdBuTheme,
        margin = F,
        xlab = NULL,
        ylab = NULL,
        scales = list(draw = FALSE)
      )
    })
  
}, ignoreInit = T)

shiny::observeEvent(input$indexChoose, {
  req(input$indexChoose)
  updateTextInput(session = session,
                  inputId = "indexIn",
                  value = input$indexChoose)
}, ignoreInit = T)

shiny::observeEvent(input$colorChoose, {
  bands <- strsplit(input$colorChoose, ",")[[1]]
  bb <- c("bandR", "bandG", "bandB")
  names(bb) <- bands
  isolate({
    for (i in bands) {
      updatePickerInput(
        session = session,
        inputId =  trimws(bb[[i]]),
        selected = trimws(i)
      )
    }
  })
}, ignoreInit = T)

output$plot1 <- renderPlot({
  req(input$bandR, input$bandG, input$bandB)
  
  plotRGB(
    myImage,
    r = isolate({
      which(input$bandR == bands.alias)
    }),
    g = isolate({
      which(input$bandG == bands.alias)
    }),
    b = isolate({
      which(input$bandB == bands.alias)
    }),
    stretch = "hist",
    main = "Clicca per firma spettrale pixel - doppio click per aggiungere"
  )
  
})

output$coordinate<-renderText({
    
    xy_str <- function(e) {
      if(is.null(e)) return("NULL\n")
      paste0("E=", as.integer(e$x ), " N=", as.integer(e$y ) )
    }  
    
    xy_str(input$plot_hover)
    
  })

observeEvent(input$plot_click, {
  
  req(input$plot_click)
  values <- gdalUtils::gdallocationinfo(img.file, input$plot_click$x,
                                input$plot_click$y, geoloc=T, valonly = T)
 
  values.num <- as.numeric(values) 
  
  x.click <- as.integer(input$plot_click$x)
  y.click <- as.integer(input$plot_click$y)

  if( input$pannelli!="firme.panel" ){
     updateTabsetPanel(session, "pannelli",
      selected = "firme.panel") 
  }
      
  plotlyProxyInvoke(plotlyProxy("graph1", session), "addTraces", list(
    list(
      x = as.integer(bands.wavelengths.nm),
      name = sprintf("(%d, %d)", x.click, y.click),
      y = values.num / 10000,
      type = 'scatter',
      mode = 'markers+lines',  line = list(shape = "spline")
    )
    
  ))
  
})

output$graph1 <- renderPlotly({
 
  input$resetGraph
 

   plot_ly(type = "scatter", mode = "markers") %>% layout(
     hoverlabel= list(align="left"),
    margin = list(l = 5, r = 2, b = 20, t = 30),
    showlegend = T, legend = list(orientation = 'h'),
    xaxis = list(title = "Lunghezza d'Onda (nm)", y=0  ),
    yaxis = list(title = "Riflettanza Bottom-Of-Atmosphere (BOA)"),
    title = sprintf("Firme spettrali"),
    shapes = rectangles
    
  )  %>%  add_markers(
       x = s2.bands$mid.wl,
       y = 0,
       name = "Info Bande",
       hovertemplate = paste(
         sep = "",
         '<b>Lunghezza d\'onda centrale</b>: %{x} nm<br>',
         '%{text}'
       ),
       text = sprintf(
         "<b>Larghezza banda nello spettro:</b> %s nm<br><b>Risoluzione spaziale pixel:</b> %s m<br><b>Descrizione:</b><br>%s",
         s2.bands$size.wl,
         s2.bands$size.pixel,
         lapply(s2.bands$desc.ita, function(x) {
           paste0(collapse = "<br>", stringi::stri_wrap(x, 30, 0.0))
         })
       ),
       
       marker = list(
         symbol = "square",
         color = "black",
         size = 9
       )
     )
   
   
})

model.names <- list(RF = "Random Forest",
                    NB = "Naive Bayes",
                    GMB = "Gradient Boosting Machine",
                    SVM= "Support Vector Machine",
                    DL = "Deep Learning")
```

**Esercizio 1:** Seleziona due combinazione di bande da assegnare ai canali dello schermo tali da: 
  1. visualizzare a colori reali l'immagine.
  2. visualizzare il NIR - near infrared
  3. un'altra combinazione a scelta

**Esercizio 2:** raccogliete 4 firme spettrali, di elementi diversi, e.g. il canale, urbanizzato, vegetazione e la zona industriale.


## Classificazione "supervisionata"

We will use only the SWIR because it is a lighter image and takes less time to process in real time and we do not want to be bored waiting for image to classify.

1. Grab some training pixels by choosing the class and start clicking on the image below.
2. Click **PLOT** if you want to redraw the points that were clicked (image is NOT auto-updated)
3. Once finished **clic "RUN"** to start training/validation/testing phase of the following models:
4. You will see a plot of signatures AND classified images



```{r  }

observeEvent(input$saveTrain, {
  
  img.file.sigs<-img.file
  raster::extension(img.file.sigs)<-"rds"
  if(file.exists(img.file.sigs)) runjs("alert('Attenzione, ho sovrascritto il file');")
  saveRDS(isolate(react$train.table), img.file.sigs)
  
})

output$plot2 <- renderPlot({
  req(input$plotTrain)
  
  req(input$bandR, input$bandG, input$bandB)
   
  plotRGB(
    myImage,
    r = which(input$bandR == bands),
    g = which(input$bandG == bands),
    b = which(input$bandB == bands),
    scale = 255,
    stretch = "hist"
  )
  
  isolate({
    if (shiny::isTruthy(react$train.table) && nrow(react$train.table)) {
      col <- RColorBrewer::brewer.pal(6, "Paired")
      col2 <- RColorBrewer::brewer.pal(6, "Pastel2")
      train.table.classes <- as.factor(react$train.table$Class)
      
      points(
        react$train.table$x,
        react$train.table$y,
        col = col[train.table.classes],
        bg = col2[train.table.classes],
        pch = 21
      )
      
      text(
        react$train.table$x,
        react$train.table$y,
        pos = 2,
        react$train.table$id,
        col = col[train.table.classes]
      )
      
    }
  })
  
})


output$trainingTable <- DT::renderDataTable( react$train.table, 
                                             extensions = 'Scroller',
                                             options = list(pageLength = 1000, 
                                                            deferRender = TRUE,
                                                            scrollY = 200,
                                                            scroller = TRUE,  
                                                            dom = 'ft'),  
                                             server = FALSE, rownames = FALSE )

observeEvent(input$resetTrain,  {
  isolate({
    react$train.table <-
      data.frame(
        id = integer(0),
        x = integer(0) ,
        y = integer(0),
        Class = character(0)
      )
  })
})

observeEvent(input$plot_dblclick,  {
 
  req(input$myClass)
  isolate({
    react$train.table <-
      rbind(
        react$train.table,
        list(
          id = as.integer(nrow(react$train.table) + 1),
          x = as.integer(input$plot_dblclick$x),
          y = as.integer(input$plot_dblclick$y),
          Class = input$myClass
        )
      )
  })
})



fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot3"))))

fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot4"))))

fluidRow(column(width = 12, shinyWidgets::addSpinner(plotOutput("plot5"))))


observeEvent(input$runTrain, {
  
  req(input$runTrain, react$train.table)
  
 # saveRDS(react$train.table, "s2.train.table.rds")
  
  if (nrow(react$train.table) < 10) {
    shinyWidgets::alert("Almeno 10 punti di ROI per classe", status =
                          "warning")
    shinyjs::alert("Almeno 10 punti di ROI per classe")
    return(NULL)
  }
  
  
  if (sum(table(react$train.table$Class) < 10) != 0) {
    whi <-
      paste0(collapse = ", ", names(which( table(
        react$train.table$Class
      ) < 10)))
    shinyWidgets::alert(
      sprintf(
        "Almeno 10 punti di ROI per classe.",
        whi
      ),
      status = "warning"
    )
    shinyjs::alert(sprintf(
      "Almeno 10 punti di ROI per classe! Classe/i %s hanno pochi punti ROI.",
      whi
    ))
    return(NULL)
  }
  
  ss <-
    matrix(
      data = NA,
      nrow = nrow(react$train.table),
      ncol = length( bands.wavelengths.nm)
    )
  
  withProgress(
    message = "Leggo le firme spettrali", 
    value = 0,
    min = 0,
    max = nrow(react$train.table),
    {
      for (i in 1:nrow(react$train.table)) {
        setProgress(as.integer(i), detail=sprintf("Punto %s", i))
        ss[i,] <-
          as.numeric(
            gdalUtils::gdallocationinfo(
              img.file, geoloc=T, 
              react$train.table[i, "x"]  ,
              react$train.table[i, "y"],
              valonly = T
            )
          )
      }
    }
  )
  
  if (is.null(ss)) {
    shinyjs::alert("ISNULL!")
    return(NULL)
  }
  
  train.data <-
    as.data.frame(cbind(react$train.table[c("Class")], ss))
  
  ###############################################################################
  ### from here  is only for plotting - our training data is  "train.data"
  quants <- c(0.1, 0.25, 0.5, 0.75, 0.9)
  df.with.ss2 <-
    train.data  %>%  dplyr::group_by(Class) %>% dplyr::summarize_all(function(x) {
      if (is.numeric(x))
        quantile(as.numeric(x), quants)
      else
        c(0, 0, 0, 0, 0)
    })
  
  df.with.ss2$Quantile <-
    rep(sprintf("Q%s", quants * 100), length(unique(df.with.ss2$Class)))
  #saveRDS(as.data.frame(df.with.ss2), "df.with.ss2.rds")
  
  df.with.ss3 <- reshape2::melt(df.with.ss2)
  df.with.ss4 <-
    reshape2::dcast(df.with.ss3 ,   Class + variable ~ Quantile)
  df.with.ss4$Wavelength <-
    bands.wavelengths.nm[df.with.ss4$variable]
  df.with.ss4[df.with.ss4 == 0] <- NA
  
  output$plot3 <- renderPlot({
    p <-
      ggplot(df.with.ss4,
             aes(
               x = Wavelength,
               y = Q50,
               group = Class,
               fill = Class,
               color = Class
             )) +
      geom_point() +
      geom_ribbon(aes(ymin = Q25,  ymax = Q75),
                  alpha = .3,
                  linetype = 0) +
      xlab("Wavelength (nm)") +
      ylab("Radiance at sensor") +
      ggtitle("Trainer signatures - Q50 and IQR") +
      theme_bw()
    print(p)
  })
  
  
  ###############################################################################
  ### from here  is AI -- our training data is  "train.data"
  ## losely from https://github.com/zia207/Satellite-Images-Classification-with-H2O-R
  train.data$Class <- as.factor(train.data$Class)
  
  ### to make things faster I  select only 40 spectral bands... 288 are too many, getting close to overfitting - BUT
  ### I use to most important ones... which are they?
  # cols<-sample(1:length(bands.wavelengths.nm), 50)
  #  train.data2<-train.data[, c("Class", as.character(cols))]
  
  names(train.data) <- c("Class", names(myImage))
  localH2o <- h2o.init(nthreads = -1, max_mem_size = "50G")
  #### Import data to H2O cluster
  train <-  as.h2o(train.data)
  myImage.df<-NULL
  withProgress(message = "Elaborazione con Algoritmi di Intelligenza Artificiale",
               detail = "Converto immagine a matrice n2D...",
               value = 0,
               {
                 myImage.df<-as.data.frame(myImage)
                 
                 setProgress(value = 0.1 ,
                             detail = "Converto matrice a oggetto h2o...")
                 
                 grid <-  as.h2o(myImage.df)
                 #grid<- as.h2o(grid.data)
                 
                 #### Split data into train, validation and test dataset
                 # splits <- h2o.splitFrame(df, c(0.75,0.125), seed=1234)
                 # train  <- h2o.assign(splits[[1]], "train.hex") # 75%
                 # valid  <- h2o.assign(splits[[2]], "valid.hex") # 12%
                 # test   <- h2o.assign(splits[[3]], "test.hex")  # 13%
                 
                 
                 
                 y <- "Class"
                 x <- setdiff(names(train.data), y)
                 models <- list()
                 setProgress(value = 0.21 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["RF"]]))

                 models[["RF"]] <- h2o.randomForest(
                   x = x,
                   y = y,
                   ntrees = 10,
                   max_depth = 5,
                   min_rows = 10,
                   binomial_double_trees = TRUE,
                   training_frame = train
                 )

                 setProgress(value = 0.24 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["NB"]]))
                 models[["NB"]]  <- h2o.naiveBayes(
                   x = x,
                   y = y,
                   training_frame = train,
                   laplace = 0,
                   nfolds = 3,
                   seed = 1234
                 )

                 setProgress(value = 0.26 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["GMB"]]))
                 models[["GMB"]]  <- h2o.gbm(
                   x = x,
                   y = y,
                   training_frame = train,
                   ntrees = 10,
                   max_depth = 3,
                   min_rows = 2,
                   learn_rate = 0.2,
                   nfolds = 3,
                   keep_cross_validation_predictions = TRUE,
                   seed = 1
                 )
                 ## Deep Learning Model
                 setProgress(value = 0.28 ,
                             detail = sprintf("Creo modello di classificazione con metodo '%s'.", model.names[["DL"]]))
                 models[["DL"]]  <- h2o.deeplearning(
                   model_id = "Deep_Learning",
                   # Destination id for this model
                   training_frame = train,
                   # Id of the training data frame
                   #  validation_frame=valid,                    # Id of the validation data frame
                   x = x,
                   # a vector predictor variable
                   y = y,
                   # name of reponse vaiables
                   standardize = TRUE,
                   # standardize the data
                   score_training_samples = 0,
                   # training set samples for scoring (0 for all)
                   activation = "RectifierWithDropout",
                   # Activation function
                   score_each_iteration = TRUE,
                   hidden = c(200, 200, 200, 200),
                   # 4 hidden layers, each of 200 neurons
                   hidden_dropout_ratios = c(0.2, 0.1, 0.1, 0),
                   # for improve generalization
                   stopping_tolerance = 0.001,
                   # tolerance for metric-based stopping criterion
                   epochs = 100,
                   # the dataset should be iterated (streamed)
                   adaptive_rate = TRUE,
                   # manually tuned learning rate
                   l1 = 1e-6,
                   # L1/L2 regularization, improve generalization
                   l2 = 1e-6,
                   max_w2 = 10,
                   # helps stability for Rectifier
                   nfolds = 3,
                   # Number of folds for K-fold cross-validation
                   fold_assignment = "Stratified",
                   # Cross-validation fold assignment scheme
                   keep_cross_validation_fold_assignment = TRUE,
                   seed = 125,
                   reproducible = TRUE,
                   variable_importances = T
                 )

                 
                 rasters <- list()
                 for (i in names(models)) {
                   setProgress(
                     value = 0.3 + length(rasters) / 100 ,
                     detail = sprintf("Applico classificazione con modello %s", model.names[[i]])
                   )
                   g.predict = as.data.frame(h2o.predict(object = models[[i]], newdata = grid))
                   rasters[[i]] <-  raster(myImage)
                   rasters[[i]][]  <-
                     factor(g.predict$predict, levels = levels(train.data$Class))
                 }
                 
                 setProgress(value = 0.4, detail = "Creo grafico...")
                 rb <- raster::brick(rasters)
                 
                 
  
  
                models.rminer<-list()
                rasters.rminer<-list()
                  
  
                # setProgress(value = 0.42, message = "Utilizzo libreria RMINER...", detail=".....")
  
         
                 setProgress(value = 0.48 ,
                             detail = sprintf("Creo modello di classificazione con metodo %s.", model.names[[ "SVM" ]] ) )
 
                models.rminer[["SVM"]] <- rminer::fit(Class~.,data=train.data, task="class",  model="ksvm", feature="s") 
                
     
                setProgress(value = 0.5 ,
                             detail = sprintf("Applico classificazione con metodo '%s'.", model.names[[ "SVM" ]] ))
                         
             
    
                 rasters.rminer[[ model.names[[ "SVM" ]]  ]] <- predict(myImage,  models.rminer[["SVM"]] )
 
                 
                models.rminer[["RF"]] <- rminer::fit(Class~.,data=train.data, task="class",  model="randomForest") 
                
                
                 print("6")
 setProgress(value = 0.6 ,
                             detail = sprintf("Applico classificazione con metodo '%s'.", model.names[[ "RF" ]] ))
                rasters.rminer[[ model.names[[ "RF" ]]  ]] <-  raster::predict(myImage,  models.rminer[["RF"]] )
                
                
                 print("7")
                models.rminer[["KNN"]] <- rminer::fit(Class~.,data=train.data, task="class",  model="knn") 
                                
 setProgress(value = 0.7 ,
                             detail = sprintf("Applico classificazione con metodo '%s'.", model.names[[ "KNN" ]] ))
                rasters.rminer[[ model.names[[ "KNN" ]]    ]] <- raster::predict(  myImage, models.rminer[["KNN"]] )


                 print("8")
                 setProgress(value = 0.89, detail = "Creo grafico...")
                 

                 
               })
  
                 print("9")
                    rb.rminer <- raster::brick(rasters.rminer)
                  output$plot5 <- renderPlot({  levelplot(rb.rminer,  xlab = "X", ylab = "Y", main="Modelli da libreria rminer")  })
  
                 print("99")
                    lu <- levelplot(rb,  xlab = "X", ylab = "Y")
                  
                  output$plot4 <- renderPlot({  lu  })
                  
                 
})



```

&nbsp;



&nbsp;


&nbsp;
